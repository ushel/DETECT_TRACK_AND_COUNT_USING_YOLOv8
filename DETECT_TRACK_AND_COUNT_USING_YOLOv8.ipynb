{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 20 17:40:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.81                 Driver Version: 560.81         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P8              8W /   35W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\DETECT_TRACK_AND_COUNT_USING_YOLOv8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Projects/DETECT_TRACK_AND_COUNT_USING_YOLOv8/1900-151662242_small.mp4\n"
     ]
    }
   ],
   "source": [
    "SOURCE_PATH_1='D:/Projects/DETECT_TRACK_AND_COUNT_USING_YOLOv8/1900-151662242_small.mp4'\n",
    "\n",
    "print(SOURCE_PATH_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_2 ='D:/Projects/DETECT_TRACK_AND_COUNT_USING_YOLOv8/2165-155327596_small.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in d:\\anaconda\\envs\\chest\\lib\\site-packages (8.3.34)\n",
      "Requirement already satisfied: numpy>=1.23.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\chest\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\envs\\chest\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\envs\\chest\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\envs\\chest\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\chest\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.34  Python-3.8.20 torch-2.4.1+cpu CPU (AMD Ryzen 9 5980HS with Radeon Graphics)\n",
      "Setup complete  (16 CPUs, 31.4 GB RAM, 14.5/244.1 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\DETECT_TRACK_AND_COUNT_USING_YOLOv8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lapx in d:\\anaconda\\envs\\chest\\lib\\site-packages (0.5.11)\n",
      "Requirement already satisfied: numpy>=1.21.6 in d:\\anaconda\\envs\\chest\\lib\\site-packages (from lapx) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lapx\n",
    "%pip install -q loguru\n",
    "%pip install -q thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "!git clone https://github.com/ifzhang/ByteTrack.git\n",
    "%cd {HOME}/ByteTrack\n",
    "\n",
    "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
    "# sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
    "\n",
    "!pip3 install -q -r requirements.txt\n",
    "!python3 setup.py -q develop\n",
    "%pip install -q cython_bbox\n",
    "%pip install -q onemetric\n",
    "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
    "%pip install -q loguru lap thop\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/ByteTrack\")\n",
    "\n",
    "\n",
    "import yolox\n",
    "print(\"yolox.__version__:\", yolox.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import sys\n",
    "sys.path.append(f\"{HOME}/ByteTrack\")\n",
    "\n",
    "import yolox\n",
    "print(\"yolox.__version__:\", yolox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
    "from onemetric.cv.utils.iou import box_iou_batch\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install RoboFlow Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install supervision==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import supervision\n",
    "print(\"supervision.__version__:\", supervision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"yolov8x.pt \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(MODEL)\n",
    "model.fuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(SOURCE_PATH_1)\n",
    "\n",
    "!yolo task=detect mode=predict model=yolov8x.pt conf=0.25 source={SOURCE_PATH_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection on frame of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervision.video.source import get_video_frames_generator\n",
    "from supervision.notebook.utils import show_frame_in_notebook\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "from supervision.draw.color import ColorPalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES_DICT = model.model.names\n",
    "CLASS_NAMES_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict mapping class_id to class_name\n",
    "CLASS_ID = [2,3,5,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on Single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_PATH_1)\n",
    "#create instance of BoxAnnotator\n",
    "box_annotator = BoxAnnotator(color = ColorPalette(), thickness = 1, text_thickness=1, text_scale=0.9)\n",
    "#acquire first video frame\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "#model prediction on single frame and conversion to supervision Detections\n",
    "results = model(frame)\n",
    "detections = Detections(\n",
    "    xyxy = results[0].boxes.xyxy.cpu().numpy(),\n",
    "    confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "    class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    ")\n",
    "\n",
    "#format custom labels\n",
    "labels = [\n",
    "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "    for _, confidence, class_id, tracker_id\n",
    "    in detections\n",
    "]\n",
    "\n",
    "#annotate and display frame\n",
    "frame= box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "show_frame_in_notebook(frame, (16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect and track whole video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class BYTETrackerArgs:\n",
    "    track_thresh: float = 0.25\n",
    "    track_buffer: int = 30\n",
    "    match_thresh: float = 0.8\n",
    "    aspect_ratio_thresh: float = 3.0\n",
    "    min_box_area: float = 1.0\n",
    "    mot20: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_2 = \"D:/Projects/DETECT_TRACK_AND_COUNT_USING_YOLOv8/2165-155327596_small.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervision.geometry.dataclasses import Point\n",
    "from supervision.video.dataclasses import VideoInfo\n",
    "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
    "from supervision.video.sink import VideoSink\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "LINE_START = Point(50, 500)\n",
    "LINE_END = Point(960-50, 500)\n",
    "\n",
    "TARGET_VIDEO_PATH = \"vehicle-counting-result.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoInfo.from_video_path(SOURCE_PATH_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
    "def detections2boxes(detections: Detections) -> np.ndarray:\n",
    "    return np.hstack((\n",
    "        detections.xyxy,\n",
    "        detections.confidence[:, np.newaxis]\n",
    "    ))\n",
    "\n",
    "\n",
    "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
    "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
    "    return np.array([\n",
    "        track.tlbr\n",
    "        for track\n",
    "        in tracks\n",
    "    ], dtype=float)\n",
    "\n",
    "\n",
    "# matches our bounding boxes with predictions\n",
    "def match_detections_with_tracks(\n",
    "    detections: Detections,\n",
    "    tracks: List[STrack]\n",
    ") -> Detections:\n",
    "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
    "        return np.empty((0,))\n",
    "\n",
    "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
    "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
    "    track2detection = np.argmax(iou, axis=1)\n",
    "\n",
    "    tracker_ids = [None] * len(detections)\n",
    "\n",
    "    for tracker_index, detection_index in enumerate(track2detection):\n",
    "        if iou[tracker_index, detection_index] != 0:\n",
    "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
    "\n",
    "    return tracker_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# open target video file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m VideoSink(TARGET_VIDEO_PATH, video_info) \u001b[38;5;28;01mas\u001b[39;00m sink:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# loop over video frames\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_frames\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;66;03m# model prediction on single frame and conversion to supervision Detections\u001b[39;00m\n\u001b[0;32m     21\u001b[0m         results \u001b[38;5;241m=\u001b[39m model(frame)\n\u001b[0;32m     22\u001b[0m         detections \u001b[38;5;241m=\u001b[39m Detections(\n\u001b[0;32m     23\u001b[0m             xyxy\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxyxy\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[0;32m     24\u001b[0m             confidence\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[0;32m     25\u001b[0m             class_id\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mcls\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     26\u001b[0m         )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\chest\\lib\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\chest\\lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# create BYTETracker instance\n",
    "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
    "# create VideoInfo instance\n",
    "video_info = VideoInfo.from_video_path(SOURCE_PATH_2)\n",
    "# create frame generator\n",
    "generator = get_video_frames_generator(SOURCE_PATH_2)\n",
    "# create LineCounter instance\n",
    "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
    "# create instance of BoxAnnotator and LineCounterAnnotator\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
    "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "# open target video file\n",
    "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
    "    # loop over video frames\n",
    "    for frame in tqdm(generator, total=video_info.total_frames):\n",
    "        # model prediction on single frame and conversion to supervision Detections\n",
    "        results = model(frame)\n",
    "        detections = Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        )\n",
    "        # filtering out detections with unwanted classes\n",
    "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # tracking detections\n",
    "        tracks = byte_tracker.update(\n",
    "            output_results=detections2boxes(detections=detections),\n",
    "            img_info=frame.shape,\n",
    "            img_size=frame.shape\n",
    "        )\n",
    "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
    "        detections.tracker_id = np.array(tracker_id)\n",
    "        # filtering out detections without trackers\n",
    "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # format custom labels\n",
    "        labels = [\n",
    "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "            for _, confidence, class_id, tracker_id\n",
    "            in detections\n",
    "        ]\n",
    "        # updating line counter\n",
    "        line_counter.update(detections=detections)\n",
    "        # annotate and display frame\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
    "        sink.write_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
